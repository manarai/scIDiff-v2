{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scIDiff Basic Usage Tutorial\n",
    "\n",
    "This notebook demonstrates the basic usage of scIDiff for single-cell RNA sequencing data modeling.\n",
    "\n",
    "## Overview\n",
    "\n",
    "scIDiff is a deep generative framework for modeling, denoising, and inverse-designing single-cell gene expression profiles using score-based diffusion models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scIDiff imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add scIDiff to Python path\n",
    "current_dir = Path.cwd()\n",
    "scidiff_path = current_dir.parent  # Assuming notebook is in scIDiff/notebooks/\n",
    "if (scidiff_path / \"scIDiff\").exists():\n",
    "    sys.path.insert(0, str(scidiff_path))\n",
    "    print(f\"‚úÖ Added {scidiff_path} to Python path\")\n",
    "else:\n",
    "    # Alternative: look in current directory\n",
    "    if (current_dir / \"scIDiff\").exists():\n",
    "        sys.path.insert(0, str(current_dir))\n",
    "        print(f\"‚úÖ Added {current_dir} to Python path\")\n",
    "    else:\n",
    "        print(\"‚ùå scIDiff not found. Please ensure you're in the correct directory.\")\n",
    "\n",
    "# Import scIDiff components\n",
    "from scIDiff.models import ScIDiffModel\n",
    "from scIDiff.data import SingleCellDataset\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Synthetic Data\n",
    "\n",
    "Let's start by creating some synthetic single-cell RNA-seq data to demonstrate scIDiff functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for synthetic data\n",
    "n_cells = 300\n",
    "n_genes = 500\n",
    "\n",
    "print(f\"üß¨ Creating synthetic scRNA-seq data...\")\n",
    "print(f\"   Cells: {n_cells}\")\n",
    "print(f\"   Genes: {n_genes}\")\n",
    "\n",
    "# Generate realistic single-cell expression data\n",
    "expression_data = np.random.lognormal(0, 1, (n_cells, n_genes))\n",
    "\n",
    "# Add sparsity (common in scRNA-seq)\n",
    "sparsity_mask = np.random.random((n_cells, n_genes)) < 0.7\n",
    "expression_data[sparsity_mask] = 0\n",
    "\n",
    "print(f\"üìä Data statistics:\")\n",
    "print(f\"   Shape: {expression_data.shape}\")\n",
    "print(f\"   Sparsity: {(expression_data == 0).mean():.1%}\")\n",
    "print(f\"   Mean expression: {expression_data.mean():.3f}\")\n",
    "print(f\"   Max expression: {expression_data.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Dataset\n",
    "\n",
    "Now let's create a scIDiff dataset from our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple dataset (no metadata for this basic example)\n",
    "dataset = SingleCellDataset(\n",
    "    expression_data=expression_data,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset created with {len(dataset)} cells\")\n",
    "print(f\"üìä Dataset statistics: {dataset.get_statistics()}\")\n",
    "\n",
    "# Test dataset indexing\n",
    "sample = dataset[0]\n",
    "print(f\"\\nüìã Sample data structure:\")\n",
    "for key, value in sample.items():\n",
    "    if torch.is_tensor(value):\n",
    "        print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value} ({type(value)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a scIDiff Model\n",
    "\n",
    "Now let's create and configure a scIDiff model for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scIDiff model\n",
    "print(\"ü§ñ Creating scIDiff model...\")\n",
    "\n",
    "model = ScIDiffModel(\n",
    "    gene_dim=n_genes,\n",
    "    hidden_dim=128,  # Smaller for demo\n",
    "    num_layers=3,    # Fewer layers for speed\n",
    "    num_timesteps=50,  # Reduced for faster sampling\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "print(f\"üì± Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Print model architecture\n",
    "print(f\"\\nüèóÔ∏è  Model architecture:\")\n",
    "print(f\"   Gene dimension: {model.gene_dim}\")\n",
    "print(f\"   Hidden dimension: {model.hidden_dim}\")\n",
    "print(f\"   Number of layers: {model.num_layers}\")\n",
    "print(f\"   Timesteps: {model.num_timesteps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Model Functionality\n",
    "\n",
    "Let's test the basic functionality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "print(\"üß™ Testing model forward pass...\")\n",
    "\n",
    "# Prepare test data\n",
    "batch_size = 4\n",
    "test_data = torch.stack([dataset[i]['expression'] for i in range(batch_size)])\n",
    "test_data = test_data.to(device)\n",
    "test_timesteps = torch.randint(0, model.num_timesteps, (batch_size,)).to(device)\n",
    "\n",
    "# Forward pass (without conditioning)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(test_data, test_timesteps)\n",
    "\n",
    "print(f\"‚úÖ Forward pass successful!\")\n",
    "print(f\"   Input shape: {test_data.shape}\")\n",
    "print(f\"   Output shape: {output.shape}\")\n",
    "print(f\"   Output range: [{output.min():.3f}, {output.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generating Samples\n",
    "\n",
    "Now let's use the model to generate synthetic single-cell expression profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "print(\"üé≤ Generating synthetic single-cell samples...\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate unconditional samples\n",
    "    generated_samples = model.sample(batch_size=10)\n",
    "\n",
    "print(f\"‚úÖ Generated {generated_samples.shape[0]} samples\")\n",
    "print(f\"   Sample shape: {generated_samples.shape}\")\n",
    "\n",
    "# Move to CPU for analysis\n",
    "generated_samples_cpu = generated_samples.cpu().numpy()\n",
    "real_data = dataset.expression_data.numpy()\n",
    "\n",
    "# Compare statistics\n",
    "print(f\"\\nüìä Comparing real vs generated data:\")\n",
    "print(f\"   Real data:\")\n",
    "print(f\"     Mean: {real_data.mean():.3f}\")\n",
    "print(f\"     Std: {real_data.std():.3f}\")\n",
    "print(f\"     Range: [{real_data.min():.3f}, {real_data.max():.3f}]\")\n",
    "print(f\"   Generated data:\")\n",
    "print(f\"     Mean: {generated_samples_cpu.mean():.3f}\")\n",
    "print(f\"     Std: {generated_samples_cpu.std():.3f}\")\n",
    "print(f\"     Range: [{generated_samples_cpu.min():.3f}, {generated_samples_cpu.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing Generated Samples\n",
    "\n",
    "Let's visualize the generated samples and compare them to real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Expression distributions\n",
    "axes[0].hist(real_data.flatten(), bins=50, alpha=0.7, label='Real', density=True)\n",
    "axes[0].hist(generated_samples_cpu.flatten(), bins=50, alpha=0.7, label='Generated', density=True)\n",
    "axes[0].set_xlabel('Expression Level')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Expression Distribution Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Mean expression per gene\n",
    "real_gene_means = real_data.mean(axis=0)\n",
    "gen_gene_means = generated_samples_cpu.mean(axis=0)\n",
    "\n",
    "axes[1].scatter(real_gene_means, gen_gene_means, alpha=0.6)\n",
    "axes[1].plot([0, real_gene_means.max()], [0, real_gene_means.max()], 'r--', alpha=0.8)\n",
    "axes[1].set_xlabel('Real Mean Expression')\n",
    "axes[1].set_ylabel('Generated Mean Expression')\n",
    "axes[1].set_title('Gene-wise Mean Expression')\n",
    "\n",
    "# Total counts per cell\n",
    "real_total_counts = real_data.sum(axis=1)\n",
    "gen_total_counts = generated_samples_cpu.sum(axis=1)\n",
    "\n",
    "axes[2].hist(real_total_counts, bins=20, alpha=0.7, label='Real', density=True)\n",
    "axes[2].hist(gen_total_counts, bins=20, alpha=0.7, label='Generated', density=True)\n",
    "axes[2].set_xlabel('Total Counts per Cell')\n",
    "axes[2].set_ylabel('Density')\n",
    "axes[2].set_title('Total Counts Distribution')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Sample comparison visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Persistence\n",
    "\n",
    "Let's demonstrate how to save and load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "print(\"üíæ Saving model...\")\n",
    "\n",
    "save_path = 'scidiff_tutorial_model.pt'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'gene_dim': n_genes,\n",
    "        'hidden_dim': 128,\n",
    "        'num_layers': 3,\n",
    "        'num_timesteps': 50,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'n_cells': n_cells,\n",
    "        'n_genes': n_genes\n",
    "    }\n",
    "}, save_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to {save_path}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîÑ Loading model...\")\n",
    "\n",
    "checkpoint = torch.load(save_path, map_location=device, weights_only=False)\n",
    "loaded_model = ScIDiffModel(**checkpoint['model_config'])\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "# Test loaded model\n",
    "with torch.no_grad():\n",
    "    loaded_samples = loaded_model.sample(batch_size=3)\n",
    "\n",
    "print(f\"‚úÖ Loaded model generates samples: {loaded_samples.shape}\")\n",
    "\n",
    "# Clean up\n",
    "os.remove(save_path)\n",
    "print(f\"üóëÔ∏è  Cleaned up temporary file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "Congratulations! You've successfully completed the scIDiff basic usage tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Tutorial completed successfully!\")\n",
    "print(\"\\nüìã What we accomplished:\")\n",
    "print(f\"   ‚úÖ Created synthetic scRNA-seq data ({n_cells} cells √ó {n_genes} genes)\")\n",
    "print(f\"   ‚úÖ Built scIDiff dataset\")\n",
    "print(f\"   ‚úÖ Created scIDiff model ({sum(p.numel() for p in model.parameters()):,} parameters)\")\n",
    "print(f\"   ‚úÖ Tested model forward pass\")\n",
    "print(f\"   ‚úÖ Generated synthetic samples\")\n",
    "print(f\"   ‚úÖ Visualized and compared data\")\n",
    "print(f\"   ‚úÖ Demonstrated model persistence\")\n",
    "\n",
    "print(\"\\nüöÄ Next steps:\")\n",
    "print(\"   üìñ Explore advanced tutorials for:\")\n",
    "print(\"      - Conditional generation\")\n",
    "print(\"      - Inverse design\")\n",
    "print(\"      - Real data analysis\")\n",
    "print(\"      - Model training\")\n",
    "print(\"   üî¨ Apply scIDiff to your own single-cell data\")\n",
    "print(\"   üìö Check the documentation for more features\")\n",
    "\n",
    "print(\"\\nüí° Key takeaways:\")\n",
    "print(\"   - scIDiff can model complex single-cell expression patterns\")\n",
    "print(\"   - The framework is flexible and easy to use\")\n",
    "print(\"   - Generated samples capture important statistical properties\")\n",
    "print(\"   - Models can be easily saved and loaded for later use\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

